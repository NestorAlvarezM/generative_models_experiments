digraph {
	graph [size="12.75,12.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139801026483200 [label="
 (1, 16)" fillcolor=darkolivegreen1]
	139801007417440 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :      (1, 1024)
mat1_sym_strides:      (1024, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (1024, 16)
mat2_sym_strides:      (1, 1024)"]
	139801007417296 -> 139801007417440
	139801007480960 [label="fc_layers.2.bias
 (16)" fillcolor=lightblue]
	139801007480960 -> 139801007417296
	139801007417296 [label=AccumulateGrad]
	139801007417248 -> 139801007417440
	139801007417248 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139801007417152 -> 139801007417248
	139801007417152 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (1, 100352)
mat1_sym_strides:    (100352, 1)
mat2            : [saved tensor]
mat2_sym_sizes  : (100352, 1024)
mat2_sym_strides:    (1, 100352)"]
	139801007417008 -> 139801007417152
	139801019962928 [label="fc_layers.0.bias
 (1024)" fillcolor=lightblue]
	139801019962928 -> 139801007417008
	139801007417008 [label=AccumulateGrad]
	139801007417056 -> 139801007417152
	139801007417056 [label="ViewBackward0
--------------------------------
self_sym_sizes: (1, 512, 14, 14)"]
	139801007416768 -> 139801007417056
	139801007416768 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	139801007416576 -> 139801007416768
	139801007416576 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139801007416480 -> 139801007416576
	139801007416480 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (512,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	139801007416288 -> 139801007416480
	139801007416288 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	139801007416048 -> 139801007416288
	139801007416048 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139801007415904 -> 139801007416048
	139801007415904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	139801007418016 -> 139801007415904
	139801007418016 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	139801007418208 -> 139801007418016
	139801007418208 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139801007418304 -> 139801007418208
	139801007418304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (128,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	139801007418400 -> 139801007418304
	139801007418400 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	139801007418592 -> 139801007418400
	139801007418592 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	139801007418688 -> 139801007418592
	139801007418688 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	139801007418784 -> 139801007418688
	139801007480880 [label="conv_layers.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	139801007480880 -> 139801007418784
	139801007418784 [label=AccumulateGrad]
	139801007418736 -> 139801007418688
	139801028123920 [label="conv_layers.0.bias
 (64)" fillcolor=lightblue]
	139801028123920 -> 139801007418736
	139801007418736 [label=AccumulateGrad]
	139801007418352 -> 139801007418304
	139801025296368 [label="conv_layers.3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	139801025296368 -> 139801007418352
	139801007418352 [label=AccumulateGrad]
	139801007418112 -> 139801007418304
	139801028007872 [label="conv_layers.3.bias
 (128)" fillcolor=lightblue]
	139801028007872 -> 139801007418112
	139801007418112 [label=AccumulateGrad]
	139801007417968 -> 139801007415904
	139801022809584 [label="conv_layers.6.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	139801022809584 -> 139801007417968
	139801007417968 [label=AccumulateGrad]
	139801007416192 -> 139801007415904
	139801027486624 [label="conv_layers.6.bias
 (256)" fillcolor=lightblue]
	139801027486624 -> 139801007416192
	139801007416192 [label=AccumulateGrad]
	139801007416336 -> 139801007416480
	139801019966368 [label="conv_layers.9.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	139801019966368 -> 139801007416336
	139801007416336 [label=AccumulateGrad]
	139801007416672 -> 139801007416480
	139801019967168 [label="conv_layers.9.bias
 (512)" fillcolor=lightblue]
	139801019967168 -> 139801007416672
	139801007416672 [label=AccumulateGrad]
	139801007417104 -> 139801007417152
	139801007417104 [label=TBackward0]
	139801007416528 -> 139801007417104
	139801017628656 [label="fc_layers.0.weight
 (1024, 100352)" fillcolor=lightblue]
	139801017628656 -> 139801007416528
	139801007416528 [label=AccumulateGrad]
	139801007417200 -> 139801007417440
	139801007417200 [label=TBackward0]
	139801007416624 -> 139801007417200
	139801019965808 [label="fc_layers.2.weight
 (16, 1024)" fillcolor=lightblue]
	139801019965808 -> 139801007416624
	139801007416624 [label=AccumulateGrad]
	139801007417440 -> 139801026483200
	dpi=150
}
